# VoiceInput å°ˆæ¡ˆç¨‹å¼ç¢¼å¯©æŸ¥å ±å‘Š

**å¯©æŸ¥æ—¥æœŸ**: 2026-02-21
**å¯©æŸ¥å·¥å…·**: GLM-4.7 (Code Reviewer Agent)
**å°ˆæ¡ˆé¡å‹**: macOS èªéŸ³è¼¸å…¥æ‡‰ç”¨ç¨‹å¼

---

## ğŸ“Š å¯©æŸ¥æ¦‚è¦

| å„ªå…ˆç´š | æ•¸é‡ | ä¸»è¦é¡åˆ¥ |
|--------|------|----------|
| P1 - åš´é‡ | 4 | è¨˜æ†¶é«”ç®¡ç†ã€ä¸¦ç™¼å®‰å…¨ã€è¼¸å…¥é©—è­‰ã€å®‰å…¨æ€§ |
| P2 - è­¦å‘Š | 4 | éŒ¯èª¤è™•ç†ã€æœ¬åœ°åŒ–ã€æ•ˆèƒ½ã€è³‡æºç®¡ç† |
| P3 - å»ºè­° | 4 | æ¸¬è©¦ã€æ–‡ä»¶ã€ç¨‹å¼ç¢¼å“è³ª |

**å»ºè­°ä¿®å¾©é †åº**: P1-1 â†’ P1-2 â†’ P1-3 â†’ P1-4 â†’ P2 é …ç›® â†’ P3 æ”¹é€²

---

## âœ… æ­£å‘è§€å¯Ÿ

1. **å„ªç§€çš„æ¶æ§‹é‡æ§‹**: å¾ `LLMManager` é‡æ§‹ç‚º `LLMProcessingService` å’Œ `LLMSettingsViewModel`ï¼Œéµå¾ªå–®ä¸€è·è²¬åŸå‰‡ (SRP)

2. **ä¾è³´æ³¨å…¥å¯¦ä½œ**: åœ¨ `VoiceInputViewModel` ä¸­ä½¿ç”¨ DI patternï¼Œæé«˜äº†å¯æ¸¬è©¦æ€§

3. **SwiftUI æœ€ä½³å¯¦è¸**: æ­£ç¢ºä½¿ç”¨ `@StateObject`ã€`@ObservedObject`ã€`@Published` ç­‰å±¬æ€§åŒ…è£å™¨

4. **å‹åˆ¥å®‰å…¨**: å–„ç”¨ Swift çš„ enum å’Œ struct ä¾†å®šç¾©æ¸…æ™°çš„å‹åˆ¥ç³»çµ±

5. **éŒ¯èª¤è™•ç†**: å®šç¾©äº†è‡ªå®šç¾©éŒ¯èª¤å‹åˆ¥ (`WhisperError`ã€`LLMError`)

---

## ğŸš¨ Priority 1 - åš´é‡å•é¡Œ (å¿…é ˆä¿®å¾©)

### 1.1 è¨˜æ†¶é«”ç®¡ç†å•é¡Œ - AudioEngine.swift

**ä½ç½®**: `VoiceInput/AudioEngine.swift`

**å•é¡Œæè¿°**:
CoreAudio ç‰©ä»¶å¯èƒ½å­˜åœ¨è¨˜æ†¶é«”æ´©æ¼é¢¨éšªï¼Œ`AudioUnit` å’Œå…¶ä»– CoreAudio è³‡æºæœªåœ¨ `deinit` ä¸­æ­£ç¢ºé‡‹æ”¾ã€‚

**ç•¶å‰å¯¦ä½œ**:

```swift
private var audioUnit: AudioUnit?
private var audioFormat: AudioStreamBasicDescription?
```

**å»ºè­°ä¿®æ­£**:

```swift
deinit {
    stopRecording()
    cleanupAudio()
}

private func cleanupAudio() {
    if let audioUnit = audioUnit {
        AudioComponentInstanceDispose(audioUnit)
        self.audioUnit = nil
    }
    // æ¸…ç†å…¶ä»– CoreAudio è³‡æº
}
```

**å½±éŸ¿**: å¯èƒ½å°è‡´é•·æœŸä½¿ç”¨å¾Œè¨˜æ†¶é«”è€—ç›¡ï¼Œæ‡‰ç”¨ç¨‹å¼å´©æ½°

---

### 1.2 ä¸¦ç™¼å®‰å…¨å•é¡Œ - VoiceInputViewModel.swift

**ä½ç½®**: `VoiceInput/VoiceInputViewModel.swift`

**å•é¡Œæè¿°**:
`@Published` å±¬æ€§åœ¨å¤šç·šç¨‹ç’°å¢ƒä¸‹å¯èƒ½ç”¢ç”Ÿç«¶æ…‹æ¢ä»¶ã€‚éŸ³è¨Šè™•ç†å’Œè½‰éŒ„å¯èƒ½åœ¨èƒŒæ™¯ç·šç¨‹åŸ·è¡Œï¼Œè€Œ UI æ›´æ–°éœ€è¦åœ¨ä¸»ç·šç¨‹ã€‚

**ç•¶å‰å¯¦ä½œ**:

```swift
@Published private(set) var isRecording = false
@Published private(set) var transcribedText = ""

func startRecording() {
    isRecording = true  // å¯èƒ½åœ¨éä¸»ç·šç¨‹å‘¼å«
    // ...
}
```

**å»ºè­°ä¿®æ­£**:

```swift
@MainActor
final class VoiceInputViewModel: ObservableObject {
    @Published private(set) var isRecording = false
    @Published private(set) var transcribedText = ""

    nonisolated func startRecording() async {
        await MainActor.run {
            isRecording = true
        }
        // èƒŒæ™¯è™•ç†...
    }
}
```

**å½±éŸ¿**: å¯èƒ½å°è‡´è³‡æ–™æå£ã€UI æ›´æ–°ç•°å¸¸ã€å´©æ½°

---

### 1.3 æœªé©—è­‰çš„ä½¿ç”¨è€…è¼¸å…¥ - SettingsView.swift

**ä½ç½®**: `VoiceInput/SettingsView.swift`

**å•é¡Œæè¿°**:
è‡ªè¨‚æ¨¡å‹è·¯å¾‘å’Œ API é‡‘é‘°æœªç¶“å……åˆ†é©—è­‰ï¼Œå¯èƒ½å°è‡´æ‡‰ç”¨ç¨‹å¼è¼‰å…¥ç„¡æ•ˆæª”æ¡ˆæˆ–é€£æ¥åˆ°ä¸å®‰å…¨çš„ç«¯é»ã€‚

**ç•¶å‰å¯¦ä½œ**:

```swift
TextField("æ¨¡å‹è·¯å¾‘", text: $viewModel.customModelPath)
```

**å»ºè­°ä¿®æ­£**:

```swift
TextField("æ¨¡å‹è·¯å¾‘", text: $viewModel.customModelPath)
    .onChange(of: viewModel.customModelPath) { newPath in
        guard !newPath.isEmpty else { return }
        validateModelPath(newPath)
    }

private func validateModelPath(_ path: String) {
    let url = URL(fileURLWithPath: path)
    // é©—è­‰æª”æ¡ˆå­˜åœ¨æ€§ã€æ¬Šé™å’Œæ ¼å¼
    guard FileManager.default.fileExists(atPath: path) else {
        // é¡¯ç¤ºéŒ¯èª¤æç¤º
        return
    }
    guard path.hasSuffix(".bin") || path.hasSuffix(".model") else {
        // é©—è­‰å‰¯æª”å
        return
    }
}
```

**å½±éŸ¿**: å¯èƒ½è¼‰å…¥æƒ¡æ„æª”æ¡ˆã€å°è‡´å´©æ½°æˆ–å®‰å…¨æ¼æ´

---

### 1.4 æ•æ„Ÿè³‡è¨Šæš´éœ²é¢¨éšª

**ä½ç½®**: å¤šå€‹æª”æ¡ˆ (LLM ç›¸é—œæ¨¡çµ„)

**å•é¡Œæè¿°**:
LLM API é‡‘é‘°å¯èƒ½è¢«æ„å¤–è¨˜éŒ„åˆ° log æˆ–éŒ¯èª¤å ±å‘Šä¸­ï¼Œé€ æˆå®‰å…¨é¢¨éšªã€‚

**å»ºè­°ä¿®æ­£**:

```swift
// åœ¨ log ä¸­é®è”½æ•æ„Ÿè³‡è¨Š
extension Logger {
    static func maskSensitive(_ text: String) -> String {
        if text.count > 8 {
            return String(text.prefix(4)) +
                   String(repeating: "*", count: text.count - 8) +
                   String(text.suffix(4))
        }
        return String(repeating: "*", count: text.count)
    }

    static func logAPIKey(_ key: String, context: String) {
        let masked = maskSensitive(key)
        print("[\(context)] API Key: \(masked)")
    }
}
```

**å½±éŸ¿**: API é‡‘é‘°æ´©æ¼ï¼Œå¯èƒ½è¢«æ¿«ç”¨ç”¢ç”Ÿè²»ç”¨

---

## âš ï¸ Priority 2 - è­¦å‘Šå•é¡Œ (æ‡‰è©²ä¿®å¾©)

### 2.1 éŒ¯èª¤è™•ç†ä¸ä¸€è‡´

**ä½ç½®**: å¤šå€‹æª”æ¡ˆ

**å•é¡Œæè¿°**:
æŸäº›å‡½æ•¸ä½¿ç”¨ `throws`ï¼ŒæŸäº›ä½¿ç”¨ `Result` å‹åˆ¥ï¼Œæœ‰äº›ç›´æ¥å¿½ç•¥éŒ¯èª¤ï¼Œå°è‡´éŒ¯èª¤è™•ç†ç­–ç•¥ä¸çµ±ä¸€ã€‚

**å»ºè­°ä¿®æ­£**:

```swift
// å®šç¾©çµ±ä¸€çš„éŒ¯èª¤å‹åˆ¥
enum AppError: LocalizedError {
    case audioRecording(Error)
    case transcription(WhisperError)
    case llmProcessing(LLMError)
    case fileIO(Error)
    case invalidInput(String)

    var errorDescription: String? {
        switch self {
        case .audioRecording(let error):
            return "éŒ„éŸ³éŒ¯èª¤: \(error.localizedDescription)"
        case .transcription(let error):
            return "è½‰éŒ„éŒ¯èª¤: \(error.localizedDescription)"
        case .llmProcessing(let error):
            return "LLM è™•ç†éŒ¯èª¤: \(error.localizedDescription)"
        case .fileIO(let error):
            return "æª”æ¡ˆæ“ä½œéŒ¯èª¤: \(error.localizedDescription)"
        case .invalidInput(let message):
            return "è¼¸å…¥ç„¡æ•ˆ: \(message)"
        }
    }
}
```

---

### 2.2 ç¡¬ç·¨ç¢¼å­—ä¸²æœªæœ¬åœ°åŒ–

**ä½ç½®**: `SettingsView.swift`ã€`ContentView.swift`

**å•é¡Œæè¿°**:
UI å­—ä¸²æœªæœ¬åœ°åŒ–ä¸”æ•£è½åœ¨ç¨‹å¼ç¢¼ä¸­ï¼Œä¸æ”¯æ´åœ‹éš›åŒ–ã€‚

**ç•¶å‰å¯¦ä½œ**:

```swift
Text("è¨­å®š")
Text("é–‹å§‹éŒ„éŸ³")
```

**å»ºè­°ä¿®æ­£**:

```swift
// å»ºç«‹ Localizable.strings
enum L10n {
    static let settings = "è¨­å®š"
    static let startRecording = "é–‹å§‹éŒ„éŸ³"
    static let stopRecording = "åœæ­¢éŒ„éŸ³"
    static let language = "èªè¨€"
    // ...
}

Text(L10n.settings)
```

---

### 2.3 Whisper è³‡æºæ¸…ç†ä¸å®Œæ•´

**ä½ç½®**: `VoiceInput/WhisperTranscriptionService.swift`

**å•é¡Œæè¿°**:
Whisper æ¨¡å‹è³‡æºå¯èƒ½æœªåœ¨ `deinit` ä¸­æ­£ç¢ºé‡‹æ”¾ã€‚

**å»ºè­°ä¿®æ­£**:

```swift
deinit {
    // ç¢ºä¿æ­£ç¢ºé‡‹æ”¾ Whisper æ¨¡å‹è³‡æº
    whisperContext?.release()
    whisperContext = nil
}
```

---

### 2.4 é »ç¹çš„ç£ç¢Ÿ I/O

**ä½ç½®**: `SettingsView.swift`

**å•é¡Œæè¿°**:
æ¯æ¬¡è¨­å®šè®Šæ›´éƒ½å¯èƒ½è§¸ç™¼ç£ç¢Ÿå¯«å…¥ï¼Œå½±éŸ¿æ•ˆèƒ½ã€‚

**å»ºè­°ä¿®æ­£**:

```swift
// ä½¿ç”¨é˜²æŠ–æ©Ÿåˆ¶
@State private var debounceTask: Task<Void, Never>?

private func saveSettingsDebounced() {
    debounceTask?.cancel()
    debounceTask = Task {
        try? await Task.sleep(nanoseconds: 500_000_000) // 0.5 ç§’
        await saveSettings()
    }
}
```

---

## ğŸ’¡ Priority 3 - å»ºè­°æ”¹é€² (è€ƒæ…®æ”¹é€²)

### 3.1 æ¸¬è©¦è¦†è“‹ç‡ä¸è¶³

**å»ºè­°**: å¢åŠ ä»¥ä¸‹æ¸¬è©¦æ¡ˆä¾‹

```swift
// è¨˜æ†¶é«”æ´©æ¼æ¸¬è©¦
func testAudioEngineMemoryCleanup() {
    let engine = AudioEngine()
    // åŸ·è¡ŒéŒ„éŸ³å¾ªç’°
    for _ in 0..<100 {
        engine.startRecording()
        engine.stopRecording()
    }
    // é©—è­‰è¨˜æ†¶é«”æ²’æœ‰ç•°å¸¸å¢é•·
}

// ä¸¦ç™¼æ“ä½œæ¸¬è©¦
func testConcurrentRecordingOperations() async {
    let viewModel = VoiceInputViewModel()
    await withTaskGroup(of: Void.self) { group in
        group.addTask { await viewModel.startRecording() }
        group.addTask { await viewModel.stopRecording() }
    }
}

// éŒ¯èª¤è·¯å¾‘æ¸¬è©¦
func testInvalidModelPathHandling() {
    let viewModel = VoiceInputViewModel()
    viewModel.customModelPath = "/invalid/path"
    XCTAssertThrowsError(try viewModel.validateSettings())
}
```

---

### 3.2 ç¨‹å¼ç¢¼æ–‡ä»¶ä¸è¶³

**å»ºè­°**: ç‚ºå…¬é–‹ API æ·»åŠ è©³ç´°æ–‡æª”è¨»è§£

```swift
/// è™•ç†èªéŸ³è½‰éŒ„çš„æœå‹™
///
/// æ­¤æœå‹™è² è²¬å”èª¿éŸ³è¨Šæ•ç²å’Œ Whisper æ¨¡å‹æ¨ç†ï¼Œ
/// æ”¯æ´å³æ™‚å’Œæ‰¹æ¬¡è½‰éŒ„æ¨¡å¼ã€‚
///
/// - Note: æ­¤é¡åˆ¥ç‚ºåŸ·è¡Œç·’å®‰å…¨
/// - Important: å¿…é ˆåœ¨ä¸»ç·šç¨‹åˆå§‹åŒ–
public final class WhisperTranscriptionService {
    /// é–‹å§‹è½‰éŒ„éŸ³è¨Šè³‡æ–™
    /// - Parameter audioData: PCM æ ¼å¼çš„éŸ³è¨Šè³‡æ–™
    /// - Returns: è½‰éŒ„å¾Œçš„æ–‡å­—çµæœ
    /// - Throws: `WhisperError.transcriptionFailed`
    public func transcribe(_ audioData: Data) async throws -> String
}
```

---

### 3.3 Magic Numbers

**ä½ç½®**: å¤šå€‹æª”æ¡ˆ

**ç•¶å‰å¯¦ä½œ**:

```swift
let sampleRate = 16000
let bufferDuration = 0.03
```

**å»ºè­°ä¿®æ­£**:

```swift
enum AudioConstants {
    static let sampleRate: Double = 16000
    static let bufferDuration: TimeInterval = 0.03
    static let maxRecordingDuration: TimeInterval = 300
    static let channels: UInt32 = 1
}
```

---

### 3.4 å‹åˆ¥æ¨æ–·å„ªåŒ–

**ç•¶å‰å¯¦ä½œ**:

```swift
let languages = ["zh-TW", "en-US", "ja-JP"]
```

**å»ºè­°ä¿®æ­£**:

```swift
let languages: [SupportedLanguage] = [
    .traditionalChinese,
    .englishUS,
    .japanese
]

enum SupportedLanguage: String, CaseIterable, Identifiable {
    case traditionalChinese = "zh-TW"
    case englishUS = "en-US"
    case japanese = "ja-JP"

    var id: String { rawValue }

    var displayName: String {
        switch self {
        case .traditionalChinese: return "ç¹é«”ä¸­æ–‡"
        case .englishUS: return "è‹±æ–‡"
        case .japanese: return "æ—¥æ–‡"
        }
    }
}
```

---

## ğŸ“‹ ä¿®å¾©å„ªå…ˆé †åº

| å„ªå…ˆé †åº | é …ç›® | é ä¼°å·¥æ™‚ | é¢¨éšªç­‰ç´š |
|---------|------|----------|----------|
| 1 | P1-1: AudioEngine è¨˜æ†¶é«”ç®¡ç† | 1-2 å°æ™‚ | é«˜ |
| 2 | P1-2: ä¸¦ç™¼å®‰å…¨å•é¡Œ | 2-4 å°æ™‚ | é«˜ |
| 3 | P1-3: è¼¸å…¥é©—è­‰ | 2-3 å°æ™‚ | ä¸­ |
| 4 | P1-4: æ•æ„Ÿè³‡è¨Šä¿è­· | 1 å°æ™‚ | ä¸­ |
| 5 | P2-1: éŒ¯èª¤è™•ç†çµ±ä¸€ | 3-4 å°æ™‚ | ä¸­ |
| 6 | P2-2: æœ¬åœ°åŒ–æ”¯æ´ | 4-6 å°æ™‚ | ä½ |
| 7 | P2-3: è³‡æºæ¸…ç† | 1 å°æ™‚ | ä½ |
| 8 | P2-4: é˜²æŠ–æ©Ÿåˆ¶ | 1 å°æ™‚ | ä½ |
| 9 | P3 é …ç›® | æŒ‰éœ€å®‰æ’ | ä½ |

---

## ğŸ¯ å»ºè­°è¡Œå‹•

1. **ç«‹å³ä¿®å¾©** (æœ¬é€±å…§): P1-1, P1-2
2. **çŸ­æœŸä¿®å¾©** (æœ¬æœˆå…§): P1-3, P1-4, P2-1
3. **ä¸­æœŸæ”¹é€²** (ä¸‹å€‹ç‰ˆæœ¬): P2-2, P2-3, P2-4
4. **é•·æœŸæ”¹é€²** (æŒçºŒé€²è¡Œ): P3 é …ç›®

---

*å ±å‘Šç”± GLM-4.7 Code Reviewer Agent ç”Ÿæˆ*
