# VoiceInput ç³»çµ±æ¶æ§‹èªªæ˜

**åˆ†ææ—¥æœŸï¼š** 2026-02-25

---

## ä¸€ã€ç³»çµ±æ¦‚è¦½

VoiceInput æ˜¯ä¸€å€‹ macOS MenuBar Appï¼Œæ ¸å¿ƒåŠŸèƒ½ç‚ºï¼šç›£è½å…¨åŸŸå¿«æ·éµ â†’ éŒ„è£½éº¥å…‹é¢¨éŸ³è¨Š â†’ èªéŸ³è½‰æ–‡å­— â†’ (å¯é¸ LLM ä¿®æ­£) â†’ è‡ªå‹•æ’å…¥åˆ°å‰æ™¯æ‡‰ç”¨ç¨‹å¼ã€‚

æ•´é«”æ¡ç”¨ **SwiftUI + MVVM + Protocol-Oriented** æ¶æ§‹ï¼Œæ­é…å¤§é‡ **ä¾è³´æ³¨å…¥ (DI)** ä»¥ä¾¿å–®å…ƒæ¸¬è©¦ã€‚

---

## äºŒã€ç³»çµ±åˆ†å±¤æ¶æ§‹åœ–

```mermaid
flowchart TB
    subgraph UI["ğŸ–¥ï¸ UI å±¤ (SwiftUI Views)"]
        direction LR
        MenuBar["MenuBarExtra\n(VoiceInputApp)"]
        ContentView["ContentView\n(ä¸»æ§/æ­·å²)"]
        Settings["SettingsView\n(è¨­å®šè¦–çª—)"]
        Floating["FloatingPanelView\n(æµ®å‹•ç‹€æ…‹é¢æ¿)"]
        SubSettings["GeneralSettingsView\nTranscriptionSettingsView\nModelSettingsView\nLLMSettingsView\nDictionarySettingsView\nHistorySettingsView"]
    end

    subgraph VM["ğŸ§  ViewModel å±¤ (ObservableObject)"]
        direction LR
        VVM["VoiceInputViewModel\nâŸ¨@MainActorâŸ©"]
        LLMVM["LLMSettingsViewModel"]
        MM["ModelManager\nâŸ¨@MainActorâŸ©"]
        HM["HistoryManager\nâŸ¨@MainActorâŸ©"]
    end

    subgraph BL["âš™ï¸ æ¥­å‹™é‚è¼¯å±¤ (Managers & Controllers)"]
        direction LR
        HIC["HotkeyInteractionController\n(å¿«æ·éµç­–ç•¥)"]
        TM["TranscriptionManager\n(è½‰éŒ„å”èª¿)"]
        PM["PermissionManager\n(æ¬Šé™ç®¡ç†)"]
        DM["DictionaryManager\n(å­—è©ç½®æ›)"]
        WM["WindowManager\n(è¦–çª—ç®¡ç†)"]
        LLMPS["LLMProcessingService\n(LLM è™•ç†)"]
    end

    subgraph SVC["ğŸ”§ æœå‹™å±¤ (Protocol + å¯¦ä½œ)"]
        direction LR
        AE["AudioEngine\n(éŸ³è¨ŠéŒ„è£½)"]
        HKM["HotkeyManager\n(å…¨åŸŸå¿«æ·éµ)"]
        IS["InputSimulator\n(éµç›¤æ¨¡æ“¬)"]
        SFS["SFSpeechTranscriptionService\n(Apple è¾¨è­˜)"]
        WTS["WhisperTranscriptionService\n(æœ¬åœ° Whisper)"]
        LLMS["LLMService\n(LLM API å‘¼å«)"]
    end

    subgraph INF["ğŸ—„ï¸ åŸºç¤å±¤ (Infrastructure)"]
        direction LR
        KH["KeychainHelper\n(é‡‘é‘°å„²å­˜)"]
        DFS["DefaultFileSystem\n(æª”æ¡ˆç³»çµ±)"]
        URLSess["URLSession\n(ç¶²è·¯)"]
        LibW["LibWhisper / whisper.xcframework\n(Whisper C API)"]
    end

    UI -->|environmentObject / @EnvironmentObject| VM
    VM --> BL
    BL --> SVC
    SVC --> INF
    WM -->|å»ºç«‹ NSPanel| Floating
```

---

## ä¸‰ã€æ ¸å¿ƒé¡åˆ¥é—œä¿‚åœ–

### 3-1 VoiceInputViewModel æ ¸å¿ƒä¾è³´

```mermaid
classDiagram
    class VoiceInputViewModel {
        <<MainActor, ObservableObject>>
        +appState: AppState
        +transcribedText: String
        +selectedLanguage: String
        +autoInsertText: Bool
        +selectedHotkey: String
        +recordingTriggerMode: String
        -hotkeyController: HotkeyInteractionController
        -cancellables: Set~AnyCancellable~
        +startRecording()
        +stopRecordingAndTranscribe()
        +performLLMCorrection()
        +toggleRecording()
        +updateHotkey(HotkeyOption)
        +updateRecordingTriggerMode(RecordingTriggerMode)
    }

    class HotkeyInteractionController {
        +mode: RecordingTriggerMode
        +isRecording: Bool
        +onStartRecording: Closure
        +onStopAndTranscribe: Closure
        +hotkeyPressed()
        +hotkeyReleased()
    }

    class TranscriptionManager {
        <<ObservableObject>>
        +transcribedText: String
        +isTranscribing: Bool
        +textProcessor: Closure
        +configure(engine:modelURL:language:)
        +startTranscription()
        +stopTranscription()
        +processAudioBuffer(AVAudioPCMBuffer)
    }

    class AudioEngineProtocol {
        <<protocol>>
        +isRecording: Bool
        +permissionGranted: Bool
        +availableInputDevices: [AudioInputDevice]
        +startRecording(callback:)
        +stopRecording()
    }

    class HotkeyManagerProtocol {
        <<protocol>>
        +currentHotkey: HotkeyOption
        +onHotkeyPressed: Closure
        +onHotkeyReleased: Closure
        +setHotkey(HotkeyOption)
        +startMonitoring()
    }

    class InputSimulatorProtocol {
        <<protocol>>
        +insertText(String)
        +checkAccessibilityPermission(showAlert:) Bool
    }

    class PermissionManager {
        <<ObservableObject, Singleton>>
        +microphoneStatus: PermissionStatus
        +speechRecognitionStatus: PermissionStatus
        +accessibilityStatus: PermissionStatus
        +checkAllPermissions()
        +requestAllPermissionsIfNeeded()
    }

    class WindowManager {
        <<Singleton>>
        +viewModel: VoiceInputViewModel
        +showFloatingWindow(isRecording:)
        +hideFloatingWindow()
    }

    VoiceInputViewModel *-- HotkeyInteractionController : owns
    VoiceInputViewModel *-- TranscriptionManager : owns
    VoiceInputViewModel --> AudioEngineProtocol : inject
    VoiceInputViewModel --> HotkeyManagerProtocol : inject
    VoiceInputViewModel --> InputSimulatorProtocol : inject
    VoiceInputViewModel --> PermissionManager : uses
    VoiceInputViewModel --> WindowManager : uses
```

### 3-2 è½‰éŒ„æœå‹™å±¤

```mermaid
classDiagram
    class TranscriptionServiceProtocol {
        <<protocol>>
        +onTranscriptionResult: Callback
        +start()
        +stop()
        +process(buffer: AVAudioPCMBuffer)
    }

    class SFSpeechTranscriptionService {
        -speechRecognizer: SFSpeechRecognizer
        -recognitionTask: SFSpeechRecognitionTask
        -audioBuffer: [AVAudioPCMBuffer]
        +updateLocale(identifier: String)
    }

    class WhisperTranscriptionService {
        <<MainActor>>
        -whisperContext: WhisperContext
        -accumulatedBuffer: [Float]
        -audioProcessingQueue: DispatchQueue
        -isRunning: Bool
        -isTranscribing: Bool
        -transcribeChunkIfNeeded() async
        -transcribeFinalIfNeeded() async
        -convertTo16kHz(buffer:) [Float]
    }

    class WhisperContext {
        -ctx: OpaquePointer
        +transcribe(samples:[Float], language:String) async String
    }

    class TranscriptionManager {
        -transcriptionService: TranscriptionServiceProtocol
        -currentConfig: TranscriptionConfig
        +textProcessor: Closure
        +configure(engine:modelURL:language:)
    }

    class TranscriptionConfig {
        <<struct>>
        +engine: SpeechRecognitionEngine
        +modelPath: String
        +language: String
    }

    TranscriptionManager --> TranscriptionServiceProtocol : uses
    SFSpeechTranscriptionService ..|> TranscriptionServiceProtocol
    WhisperTranscriptionService ..|> TranscriptionServiceProtocol
    WhisperTranscriptionService --> WhisperContext : owns
    TranscriptionManager --> TranscriptionConfig : uses
```

### 3-3 LLM æœå‹™å±¤

```mermaid
classDiagram
    class LLMSettingsViewModel {
        <<ObservableObject>>
        +llmEnabled: Bool
        +llmProvider: String
        +llmAPIKey: String
        +llmModel: String
        +llmPrompt: String
        +customProviders: [CustomLLMProvider]
        +resolveEffectiveConfiguration() EffectiveLLMConfiguration
        +loadAPIKey(for:customId:)
        +addCustomProvider()
        +removeCustomProvider()
    }

    class LLMProcessingService {
        <<Singleton>>
        +process(text:config:logger:completion:)
    }

    class LLMService {
        <<Singleton>>
        -networkProvider: NetworkProviderProtocol
        +correctText(text:prompt:provider:apiKey:url:model:) async
        -callOpenAI() async String
        -callAnthropic() async String
        -callOllama() async String
        -callCustomAPI() async String
        -parseOpenAILikeResponse(data:) String
        -parseAnthropicResponse(data:) String
    }

    class NetworkProviderProtocol {
        <<protocol>>
        +data(for: URLRequest) async (Data, URLResponse)
    }

    class KeychainHelper {
        <<Singleton>>
        +save(_:service:account:)
        +read(service:account:) String?
        +delete(service:account:)
    }

    class EffectiveLLMConfiguration {
        <<struct>>
        +prompt: String
        +provider: LLMProvider
        +apiKey: String
        +url: String
        +model: String
    }

    class CustomLLMProvider {
        <<struct>>
        +id: UUID
        +name: String
        +url: String
        +model: String
        +prompt: String
    }

    LLMSettingsViewModel --> KeychainHelper : saves API key
    LLMSettingsViewModel --> CustomLLMProvider : manages
    LLMSettingsViewModel --> EffectiveLLMConfiguration : produces
    LLMProcessingService --> LLMService : delegates
    LLMService --> NetworkProviderProtocol : inject
    LLMService --> EffectiveLLMConfiguration : consumes
```

### 3-4 Model èˆ‡ History ç®¡ç†

```mermaid
classDiagram
    class ModelManager {
        <<MainActor, ObservableObject>>
        +importedModels: [ImportedModel]
        +whisperModelPath: String
        +isImportingModel: Bool
        +modelImportProgress: Double
        +modelsDirectory: URL
        +importModel()
        +importModelFromURL(URL)
        +deleteModel(ImportedModel)
        +selectModel(ImportedModel)
        +getSelectedModelURL() URL?
    }

    class ImportedModel {
        <<struct, Codable>>
        +id: UUID
        +name: String
        +fileName: String
        +fileSize: Int64?
        +importDate: Date
        +fileSizeFormatted: String
        +inferredModelType: String
        +fileExists(in:) Bool
    }

    class HistoryManager {
        <<MainActor, ObservableObject>>
        +transcriptionHistory: [TranscriptionHistoryItem]
        +addHistoryIfNeeded(String)
        +deleteHistoryItem(TranscriptionHistoryItem)
        +copyHistoryText(String)
    }

    class TranscriptionHistoryItem {
        <<struct, Codable>>
        +id: UUID
        +text: String
        +createdAt: Date
    }

    class FileSystemProtocol {
        <<protocol>>
        +fileExists(atPath:) Bool
        +data(contentsOf:) Data
        +createDirectory(at:withIntermediateDirectories:)
        +write(_:to:options:)
        +removeItem(at:)
        +copyItem(at:to:)
        +getFileSize(at:) Int64
    }

    class DefaultFileSystem {
        <<Singleton>>
        -manager: FileManager
    }

    ModelManager --> FileSystemProtocol : inject
    ModelManager --> ImportedModel : manages
    HistoryManager --> FileSystemProtocol : inject
    HistoryManager --> TranscriptionHistoryItem : manages
    DefaultFileSystem ..|> FileSystemProtocol
```

---

## å››ã€å”è­°èˆ‡å¯¦ä½œå°æ‡‰åœ–

```mermaid
classDiagram
    direction LR

    class AudioEngineProtocol { <<protocol>> }
    class HotkeyManagerProtocol { <<protocol>> }
    class InputSimulatorProtocol { <<protocol>> }
    class TranscriptionServiceProtocol { <<protocol>> }
    class FileSystemProtocol { <<protocol>> }
    class NetworkProviderProtocol { <<protocol>> }
    class KeychainProtocol { <<protocol>> }

    class AudioEngine { <<Singleton>> }
    class HotkeyManager { <<Singleton>> }
    class InputSimulator { <<Singleton>> }
    class SFSpeechTranscriptionService { }
    class WhisperTranscriptionService { }
    class DefaultFileSystem { <<Singleton>> }
    class URLSession { <<System>> }
    class KeychainHelper { <<Singleton>> }

    class MockAudioEngine { <<Test Mock>> }
    class MockHotkeyManager { <<Test Mock>> }
    class MockInputSimulator { <<Test Mock>> }
    class MockNetworkProvider { <<Test Mock>> }
    class MockFileSystem { <<Test Mock>> }

    AudioEngine ..|> AudioEngineProtocol
    MockAudioEngine ..|> AudioEngineProtocol

    HotkeyManager ..|> HotkeyManagerProtocol
    MockHotkeyManager ..|> HotkeyManagerProtocol

    InputSimulator ..|> InputSimulatorProtocol
    MockInputSimulator ..|> InputSimulatorProtocol

    SFSpeechTranscriptionService ..|> TranscriptionServiceProtocol
    WhisperTranscriptionService ..|> TranscriptionServiceProtocol

    DefaultFileSystem ..|> FileSystemProtocol
    MockFileSystem ..|> FileSystemProtocol

    URLSession ..|> NetworkProviderProtocol
    MockNetworkProvider ..|> NetworkProviderProtocol

    KeychainHelper ..|> KeychainProtocol
```

---

## äº”ã€éŒ„éŸ³åˆ°è¼¸å…¥çš„å®Œæ•´åºåˆ—åœ–

```mermaid
sequenceDiagram
    actor User as ä½¿ç”¨è€…
    participant HKM as HotkeyManager
    participant HIC as HotkeyInteractionController
    participant VVM as VoiceInputViewModel
    participant AE as AudioEngine
    participant TM as TranscriptionManager
    participant WTS as WhisperTranscriptionService
    participant LLM as LLMService
    participant IS as InputSimulator
    participant WM as WindowManager

    User->>HKM: æŒ‰ä¸‹å¿«æ·éµ (fn/Cmd/Option)
    HKM->>HKM: processFlagsChangedEvent()
    HKM->>HIC: onHotkeyPressed()

    alt pressAndHold æ¨¡å¼
        HIC->>VVM: onStartRecording()
    else toggle æ¨¡å¼ï¼ˆé–’ç½®ä¸­ï¼‰
        HIC->>VVM: onStartRecording()
    end

    VVM->>TM: configure(engine:whisper, modelURL:, language:)
    VVM->>WM: showFloatingWindow(isRecording: true)
    WM-->>User: é¡¯ç¤ºæµ®å‹•é¢æ¿ï¼ˆéŒ„éŸ³ä¸­ğŸ™ï¸ï¼‰
    VVM->>TM: startTranscription()
    VVM->>AE: startRecording(callback:)
    AE-->>VVM: é–‹å§‹ç”¢ç”Ÿ AVAudioPCMBuffer

    loop éŒ„éŸ³æœŸé–“æ¯ 1 ç§’
        AE->>TM: processAudioBuffer(buffer)
        TM->>WTS: process(buffer:)
        WTS->>WTS: convertTo16kHz()
        WTS->>WTS: transcribeChunkIfNeeded()
        WTS-->>TM: onTranscriptionResult(.success(partialText))
        TM->>TM: textProcessorï¼ˆç°¡è½‰ç¹ + å­—å…¸ï¼‰
        TM-->>VVM: $transcribedText æ›´æ–°
        VVM-->>User: æµ®å‹•é¢æ¿é¡¯ç¤ºå³æ™‚æ–‡å­—
    end

    User->>HKM: æ”¾é–‹å¿«æ·éµï¼ˆæˆ–å†æŒ‰ä¸€æ¬¡ï¼‰
    HKM->>HIC: onHotkeyReleased()
    HIC->>VVM: onStopAndTranscribe()

    VVM->>AE: stopRecording()
    VVM->>TM: stopTranscription()
    VVM->>WM: showFloatingWindow(isRecording: false)
    WM-->>User: æµ®å‹•é¢æ¿ï¼ˆè½‰å¯«ä¸­âŸ³ï¼‰

    WTS->>WTS: transcribeFinalIfNeeded()
    WTS-->>TM: onTranscriptionResult(.success(finalText))
    TM-->>VVM: $transcribedText æœ€çµ‚æ–‡å­—

    alt llmEnabled == true
        VVM->>LLM: correctText(text:, provider:, apiKey:...)
        LLM-->>VVM: correctedText
        VVM->>VVM: toTraditionalChinese() + replaceText()
        VVM-->>User: æµ®å‹•é¢æ¿ï¼ˆå¢å¼·ä¸­âš¡ï¼‰
    end

    VVM->>VVM: addHistoryIfNeeded()

    alt autoInsertText == true
        VVM->>IS: insertText(transcribedText)
        IS->>IS: pasteText() â†’ Cmd+V æ¨¡æ“¬
        IS-->>User: æ–‡å­—æ’å…¥åˆ°å‰æ™¯ App
    end

    VVM->>WM: hideFloatingWindow()
    WM-->>User: æµ®å‹•é¢æ¿éš±è—
```

---

## å…­ã€å¿«æ·éµç‹€æ…‹æ©Ÿ

```mermaid
stateDiagram-v2
    [*] --> Idle : App å•Ÿå‹•

    state "pressAndHold æ¨¡å¼" as PAH {
        [*] --> PAH_Idle
        PAH_Idle --> PAH_Recording : hotkeyPressed()\nâ†’ onStartRecording()
        PAH_Recording --> PAH_Idle : hotkeyReleased()\nâ†’ onStopAndTranscribe()
        note right of PAH_Recording : é˜²æŠ–ï¼š< 300ms å¿½ç•¥æ”¾é–‹
    }

    state "toggle æ¨¡å¼" as TGL {
        [*] --> TGL_Idle
        TGL_Idle --> TGL_Transitioning1 : hotkeyPressed()
        TGL_Transitioning1 --> TGL_Recording : 300ms debounce å®Œæˆ\nâ†’ onStartRecording()
        TGL_Recording --> TGL_Transitioning2 : hotkeyPressed()
        TGL_Transitioning2 --> TGL_Idle : 300ms debounce å®Œæˆ\nâ†’ onStopAndTranscribe()
        TGL_Transitioning1 --> TGL_Transitioning1 : é˜²é‡å…¥ï¼šå¿½ç•¥å¿«é€Ÿé€£æ“Š
        TGL_Transitioning2 --> TGL_Transitioning2 : é˜²é‡å…¥ï¼šå¿½ç•¥å¿«é€Ÿé€£æ“Š
    }

    state "AppState ä¸»ç‹€æ…‹æ©Ÿ" as APPSTATE {
        [*] --> idle
        idle --> recording : startRecording()
        recording --> transcribing : stopRecordingAndTranscribe()
        transcribing --> enhancing : llmEnabled == true
        transcribing --> idle : llmEnabled == false\n(éš±è—è¦–çª—)
        enhancing --> idle : LLM å®Œæˆ\n(éš±è—è¦–çª—)
        recording --> idle : éŒ„éŸ³å¤±æ•—\n(2s å¾Œæ¢å¾©)
    }
```

---

## ä¸ƒã€LLM Provider é¸æ“‡æµç¨‹

```mermaid
flowchart TD
    A[ä½¿ç”¨è€…é–‹å•Ÿ LLM è¨­å®š] --> B{é¸æ“‡ Provider}

    B --> C[OpenAI]
    B --> D[Anthropic]
    B --> E[Ollama]
    B --> F[è‡ªè¨‚ Provider]

    C --> C1[è¼¸å…¥ API Key\nå„²å­˜åˆ° Keychain]
    C --> C2[è¨­å®šæ¨¡å‹åç¨±\ngpt-4o-mini é è¨­]

    D --> D1[è¼¸å…¥ API Key\nå„²å­˜åˆ° Keychain]
    D --> D2[è¨­å®šæ¨¡å‹åç¨±\nclaude-3-haiku é è¨­]

    E --> E1[è¨­å®š URL\nlocalhost:11434 é è¨­]
    E --> E2[è¨­å®šæ¨¡å‹åç¨±\nllama3 é è¨­]

    F --> F1[æ–°å¢ CustomLLMProvider\n{åç¨±, URL, æ¨¡å‹, Prompt}]
    F --> F2[API Key å­˜å…¥ Keychain\nä»¥ UUID ç‚º account key]

    C1 & C2 & D1 & D2 & E1 & E2 & F1 & F2 --> G[resolveEffectiveConfiguration()]

    G --> H[EffectiveLLMConfiguration\n{prompt, provider, apiKey, url, model}]

    H --> I[LLMProcessingService.process()]
    I --> J[LLMService.correctText()]

    J --> K{provider}
    K --> L[callOpenAI\nPOST api.openai.com]
    K --> M[callAnthropic\nPOST api.anthropic.com]
    K --> N[callOllama\nPOST localhost:11434/v1/chat/completions]
    K --> O[callCustomAPI\nPOST è‡ªè¨‚ URL]

    L & M & N & O --> P[parseResponse]
    P --> Q{æˆåŠŸ?}
    Q --> |Yes| R[ä¿®æ­£å¾Œæ–‡å­—å›å‚³ VoiceInputViewModel]
    Q --> |No| S[LLMServiceError\nâ†’ lastLLMError é¡¯ç¤ºæ–¼æµ®å‹•é¢æ¿]
```

---

## å…«ã€è³‡æ–™æŒä¹…åŒ–ç­–ç•¥

```mermaid
flowchart LR
    subgraph UserDefaults["UserDefaults / @AppStorage"]
        UD1["selectedLanguage\né¸æ“‡èªè¨€"]
        UD2["selectedHotkey\nå¿«æ·éµ"]
        UD3["recordingTriggerMode\nè§¸ç™¼æ¨¡å¼"]
        UD4["autoInsertText\nè‡ªå‹•æ’å…¥"]
        UD5["selectedSpeechEngine\nèªéŸ³å¼•æ“"]
        UD6["whisperModelPath\næ¨¡å‹è·¯å¾‘"]
        UD7["llmEnabled / llmProvider\nllmModel / llmPrompt\nllmURL"]
        UD8["importedModels (JSON)\nå·²åŒ¯å…¥æ¨¡å‹åˆ—è¡¨"]
        UD9["customProvidersData (JSON)\nè‡ªè¨‚ Provider åˆ—è¡¨"]
        UD10["builtInProviderSettingsData (JSON)\nå…§å»º Provider è¨­å®š"]
    end

    subgraph Keychain["Keychain (KeychainHelper)"]
        KC1["llmAPIKey.OpenAI\nOpenAI API Key"]
        KC2["llmAPIKey.Anthropic\nAnthropic API Key"]
        KC3["llmAPIKey.{UUID}\nè‡ªè¨‚ Provider API Key"]
    end

    subgraph File["Application Support ç›®éŒ„"]
        F1["Models/\n*.bin Whisper æ¨¡å‹æª”æ¡ˆ"]
        F2["transcription_history.json\næœ€è¿‘ 10 ç­†è½‰éŒ„è¨˜éŒ„"]
    end

    VoiceInputViewModel --> UD1 & UD2 & UD3 & UD4 & UD5
    ModelManager --> UD6 & UD8
    LLMSettingsViewModel --> UD7 & UD9 & UD10
    LLMSettingsViewModel --> KC1 & KC2 & KC3
    ModelManager --> F1
    HistoryManager --> F2
```

---

## ä¹ã€æ¶æ§‹ç‰¹è‰²èˆ‡è¨­è¨ˆæ±ºç­–æ‘˜è¦

### å”è­°é©…å‹•è¨­è¨ˆ (Protocol-Oriented Design)
æ‰€æœ‰æ ¸å¿ƒæœå‹™å‡å®šç¾©æ–¼å”è­°ï¼ˆ`AudioEngineProtocol`ã€`HotkeyManagerProtocol` ç­‰ï¼‰ï¼Œå¯¦éš›å¯¦ä½œèˆ‡æ¸¬è©¦ Mock å‡å¯¦ä½œç›¸åŒå”è­°ã€‚`VoiceInputViewModel` é€éå»ºæ§‹å­æ³¨å…¥ï¼Œå¯åœ¨æ¸¬è©¦ä¸­æ›¿æ›ç‚º Mockï¼Œä¸éœ€è¦å•Ÿå‹•çœŸæ­£çš„éº¥å…‹é¢¨æˆ–å¿«æ·éµç›£è½ã€‚

### åˆ†å±¤è·è²¬åˆ†é›¢
| å±¤æ¬¡ | è² è²¬ç¯„åœ | ä»£è¡¨é¡åˆ¥ |
|------|---------|---------|
| UI å±¤ | ç•«é¢æ¸²æŸ“ã€ä½¿ç”¨è€…äº’å‹• | `ContentView`ã€`FloatingPanelView` |
| ViewModel å±¤ | æ‡‰ç”¨ç¨‹å¼ç‹€æ…‹ã€æ¥­å‹™å”èª¿ | `VoiceInputViewModel`ã€`LLMSettingsViewModel` |
| Controller å±¤ | å–®ä¸€è·è²¬çš„è½‰æ›é‚è¼¯ | `HotkeyInteractionController`ã€`TranscriptionManager` |
| æœå‹™å±¤ | ç³»çµ± API å°è£ | `AudioEngine`ã€`HotkeyManager`ã€`LLMService` |
| åŸºç¤å±¤ | å¹³å°æŠ½è±¡ | `DefaultFileSystem`ã€`KeychainHelper` |

### è³‡æ–™å®‰å…¨ç­–ç•¥
- **API Key** ä¸€å¾‹å­˜å…¥ **Keychain**ï¼Œä¸å­˜æ–¼ UserDefaults
- æ¯å€‹ Providerï¼ˆåŒ…å«è‡ªè¨‚ï¼‰ä»¥ç¨ç«‹ account key å­˜å„²ï¼Œäº’ä¸å¹²æ“¾
- å¯¦éš› API è«‹æ±‚å‰é‡æ–°å¾ Keychain è®€å–ï¼Œç¢ºä¿ä½¿ç”¨æœ€æ–°é‡‘é‘°

### ä¸¦ç™¼ç­–ç•¥
- `VoiceInputViewModel`ã€`ModelManager`ã€`HistoryManager` æ¨™è¨˜ `@MainActor`
- `WhisperTranscriptionService` çš„éŸ³è¨Šè™•ç†åœ¨ç¨ç«‹ `DispatchQueue` åŸ·è¡Œï¼Œåˆ‡å› MainActor æ‰ä¿®æ”¹ç‹€æ…‹
- `HotkeyManager` çš„ CGEventTap callback é€é `DispatchQueue.main.async` å›åˆ°ä¸»åŸ·è¡Œç·’

### å¿«æ·éµæ¶æ§‹ï¼ˆä¸‰å±¤è§£è€¦ï¼‰
```
CGEventTapï¼ˆç³»çµ±å±¤ï¼‰
    â†“ keyCode + flags
HotkeyManagerï¼ˆè¨Šè™Ÿå±¤ï¼‰â€” ç´”ç²¹çš„ã€ŒæŒ‰ä¸‹/æ”¾é–‹ã€äº‹ä»¶æ´¾é€
    â†“ onPressed / onReleased
HotkeyInteractionControllerï¼ˆç­–ç•¥å±¤ï¼‰â€” ä¾æ¨¡å¼æ±ºå®šèªæ„
    â†“ onStartRecording / onStopAndTranscribe
VoiceInputViewModelï¼ˆæ¥­å‹™å±¤ï¼‰â€” åŸ·è¡ŒéŒ„éŸ³æµç¨‹
```
